#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=InstallLLaMaEnvironment
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=00:30:00
#SBATCH --output=install_llama_env-%A.out

#exit if an error occurs
set -e 

module purge
module load 2022
module load Miniconda3/4.12.0
module load CUDA/11.7.0


conda create -n llama_3_instruct python=3.10 -y
source activate llama_3_instruct

pip install --upgrade pip
pip install -r requirements_llama_three.txt

pip install openpyxl
pip install transformers==4.40.0
conda install -c conda-forge code-server
