============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
[2024-05-25 18:03:01,162] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-25 18:03:08,275] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3: setting --include=localhost:0,1,2,3
[2024-05-25 18:03:08,275] [INFO] [runner.py:555:main] cmd = /home/scur0405/.conda/envs/llamavid/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llamavid/train/train_mem.py --deepspeed ./scripts/zero2_offload.json --model_name_or_path ./work_dirs/llama-vid/llama-vid-7b-full-224-video-fps-1 --version imgsp_v1 --data_path ./data/LLaMA-VID-Finetune/animal-grounding/train_grounding_animals.json --image_folder ./data/LLaMA-VID-Finetune --video_folder ./data/LLaMA-VID-Finetune --vision_tower ./model_zoo/LAVIS/eva_vit_g.pth --image_processor ./llamavid/processor/clip-patch14-224 --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length False --video_fps 1 --video_token 2 --bert_type qformer_pretrain_freeze_all --num_query 32 --compress_type mean --bf16 True --output_dir ./work_dirs/finetuning-grounding-animals-fps-1-ckpt --num_train_epochs 1 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 2 --evaluation_strategy no --save_strategy steps --save_steps 200 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 65536 --gradient_checkpointing True --dataloader_num_workers 1 --lazy_preprocess True --report_to wandb
[2024-05-25 18:03:09,691] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-25 18:03:11,800] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2024-05-25 18:03:11,800] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2024-05-25 18:03:11,800] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2024-05-25 18:03:11,800] [INFO] [launch.py:163:main] dist_world_size=4
[2024-05-25 18:03:11,800] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
/home/scur0405/.conda/envs/llamavid/bin/python: can't open file '/gpfs/home4/scur0405/LLaMA-VID/llamavid/train/train_mem.py': [Errno 2] No such file or directory
/home/scur0405/.conda/envs/llamavid/bin/python: can't open file '/gpfs/home4/scur0405/LLaMA-VID/llamavid/train/train_mem.py': [Errno 2] No such file or directory
/home/scur0405/.conda/envs/llamavid/bin/python: can't open file '/gpfs/home4/scur0405/LLaMA-VID/llamavid/train/train_mem.py': [Errno 2] No such file or directory
/home/scur0405/.conda/envs/llamavid/bin/python: can't open file '/gpfs/home4/scur0405/LLaMA-VID/llamavid/train/train_mem.py': [Errno 2] No such file or directory
[2024-05-25 18:03:12,803] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 1229765
[2024-05-25 18:03:12,819] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 1229766
[2024-05-25 18:03:12,833] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 1229767
[2024-05-25 18:03:12,846] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 1229768
[2024-05-25 18:03:12,846] [ERROR] [launch.py:321:sigkill_handler] ['/home/scur0405/.conda/envs/llamavid/bin/python', '-u', 'llamavid/train/train_mem.py', '--local_rank=3', '--deepspeed', './scripts/zero2_offload.json', '--model_name_or_path', './work_dirs/llama-vid/llama-vid-7b-full-224-video-fps-1', '--version', 'imgsp_v1', '--data_path', './data/LLaMA-VID-Finetune/animal-grounding/train_grounding_animals.json', '--image_folder', './data/LLaMA-VID-Finetune', '--video_folder', './data/LLaMA-VID-Finetune', '--vision_tower', './model_zoo/LAVIS/eva_vit_g.pth', '--image_processor', './llamavid/processor/clip-patch14-224', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'False', '--video_fps', '1', '--video_token', '2', '--bert_type', 'qformer_pretrain_freeze_all', '--num_query', '32', '--compress_type', 'mean', '--bf16', 'True', '--output_dir', './work_dirs/finetuning-grounding-animals-fps-1-ckpt', '--num_train_epochs', '1', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '200', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '65536', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '1', '--lazy_preprocess', 'True', '--report_to', 'wandb'] exits with return code = 2

JOB STATISTICS
==============
Job ID: 6382029
Cluster: snellius
User/Group: scur0405/scur0405
State: RUNNING
Nodes: 1
Cores per node: 72
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:32:24 core-walltime
Job Wall-clock time: 00:00:27
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 480.00 GB (480.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
